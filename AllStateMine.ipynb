{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox, skew\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID = test.id\n",
    "loss = train.loss\n",
    "\n",
    "train = train.drop(['id','loss'], axis=1)\n",
    "test = test.drop(['id'], axis=1)\n",
    "\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat_cols = [x for x in train.select_dtypes(include=['object']).columns]\n",
    "cont_cols = [x for x in train.select_dtypes(exclude=['object']).columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Putting a semi-colon in the end will stop Ipython to display <matplotlib ....> description\n",
    "pd.DataFrame.hist(train,column=cont_cols, figsize=(15,15), sharex=True, sharey=True, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Check the skew in continuous variables in the train dataset\n",
    "skewed_feats = train[cont_cols].apply(lambda x: skew(x.dropna()))\n",
    "print(skewed_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skewed_feats = skewed_feats[skewed_feats > 0.38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Apply Boxcox tranformation to reduce the skew in the train dataset\n",
    "for column in skewed_feats.index:\n",
    "    if column == 'cont9' :\n",
    "        train[column] = train[column]\n",
    "        train[column], lam = boxcox(train[column])\n",
    "        print(column + \" : \" + str(lam))\n",
    "    else:\n",
    "        train[column] = train[column] + 1.0\n",
    "        train[column], lam = boxcox(train[column]) \n",
    "        print(column + \" : \" + str(lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.hist(train,column=cont_cols, figsize=(10,10), sharex=True, sharey=True, bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plotting the continuous variables in the train dataset after removing skewness\n",
    "sns.set_style('ticks')\n",
    "with sns.color_palette('Reds_r'):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for column in cont_cols:\n",
    "        sns.kdeplot(train[column], shade=True);\n",
    "        plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skewed_feats = test[cont_cols].apply(lambda x: skew(x.dropna()))\n",
    "print(skewed_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skewed_feats = skewed_feats[skewed_feats > 0.36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Apply boxcox tranformation for the continuous variables in test set\n",
    "for column in skewed_feats.index:\n",
    "    if column == 'cont9' :\n",
    "        test[column], lam = boxcox(test[column])\n",
    "        print(column + \" : \" + str(lam))\n",
    "    else:\n",
    "        test[column] = test[column] + 1.0\n",
    "        test[column], lam = boxcox(test[column]) \n",
    "        print(column + \" : \" + str(lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## After removing skewness in the test set\n",
    "sns.set_style('ticks')\n",
    "with sns.color_palette('Reds_r'):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for column in cont_cols:\n",
    "        sns.kdeplot(test[column], shade=True)\n",
    "        plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Detect the outliers in the train dataset\n",
    "\n",
    "from collections import defaultdict\n",
    "outliers_count = defaultdict(lambda : 0)  ## For counting the datapoints that are outliers for each feature\n",
    "df = train[cont_cols]\n",
    "\n",
    "for feature in cont_cols:\n",
    "    Q1 = np.percentile(df[feature],25.0)  \n",
    "    Q3 = np.percentile(df[feature],75.0)\n",
    "    step = 1.5*(Q3-Q1)\n",
    "    \n",
    "    #Define a dataframe that contains all the outliers\n",
    "    outliers_df = (df[~((df[feature] >= Q1-step) & (df[feature] <= Q3+step))])\n",
    "    \n",
    "    ## Count of outliers\n",
    "    for index in outliers_df.index.values:\n",
    "        outliers_count[index] +=1\n",
    "\n",
    "## Define a list that contains data points which are outliers for more than one feature        \n",
    "max_outliers_count = [] \n",
    "\n",
    "## Count the number of features for which a data point is an outlier\n",
    "max_features_count = set()\n",
    "\n",
    "for key in outliers_count.keys():\n",
    "    if outliers_count[key]> 1:\n",
    "        max_features_count.add(outliers_count[key])\n",
    "print(max_features_count)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## We see that there are data points which are outliers for features in the range[2,6].\n",
    "##Count the datapoints which are ouliers for more than one feature\n",
    "\n",
    "for i in range(2,6):\n",
    "    max_outliers_count = []\n",
    "    for key in outliers_count.keys():\n",
    "        if outliers_count[key] == i:\n",
    "            max_outliers_count.append((key, outliers_count[key]))\n",
    "    print(\"Datapoints which are outliers for \" + str(i) + \" features : \" , len(max_outliers_count))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Remove all the data points from train set which are outliers for more than one feature\n",
    "outliers_index = []\n",
    "\n",
    "for key in outliers_count.keys():\n",
    "        if outliers_count[key] > 1:\n",
    "            outliers_index.append(key)\n",
    "            \n",
    "print(\"Total count : \", len(outliers_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.drop(train.index[outliers_index]).reset_index(drop=True)\n",
    "\n",
    "print(\"New train size : \", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Scale the continuous data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "new_cont_feats = train[cont_cols]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(new_cont_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Transform the continuous train dataset with the scaler\n",
    "train[cont_cols] = scaler.transform(new_cont_feats)\n",
    "\n",
    "## Plot the continuous data in train set after scaling\n",
    "sns.set_style('ticks')\n",
    "with sns.color_palette('Reds_r'):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for column in cont_cols:\n",
    "        sns.kdeplot(train[column], shade=True)\n",
    "        plt.legend(loc=2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Transform the continuous features in the  test set using the above scaler\n",
    "test[cont_cols] = scaler.transform(test[cont_cols])\n",
    "    \n",
    "## Plot after scaling the test set\n",
    "sns.set_style('ticks')\n",
    "with sns.color_palette('Reds_r'):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for column in cont_cols:\n",
    "        sns.kdeplot(test[column], shade=True)\n",
    "        plt.legend(loc=2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_df = train[cont_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Check for correlation in the train set\n",
    "corr = cont_df.corr()\n",
    "\n",
    "##Drop first and last column from corr \n",
    "corr.drop(['cont1'], axis=0, inplace = True)\n",
    "corr.drop(['cont14'], axis=1, inplace = True)\n",
    "\n",
    "## Create a mask so that we have the correlation values once\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask,1)] = True\n",
    "\n",
    "##Plot the heatmap\n",
    "with sns.axes_style('white'):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    sns.heatmap(corr, mask=mask, annot=True, cmap='RdBu', fmt='+.2f', cbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_df = test[cont_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Check for correlation in the test set\n",
    "corr = cont_df.corr()\n",
    "\n",
    "##Drop first and last column from corr \n",
    "corr.drop(['cont1'], axis=0, inplace = True)\n",
    "corr.drop(['cont14'], axis=1, inplace = True)\n",
    "\n",
    "## Create a mask so that we have the correlation values once\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask,1)] = True\n",
    "\n",
    "##Plot the heatmap\n",
    "with sns.axes_style('white'):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    sns.heatmap(corr, mask=mask, annot=True, cmap='RdBu', fmt='+.2f', cbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Combine train-test in order to convert the categorical variables\n",
    "train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "\n",
    "## Enocde the categorical data\n",
    "for column in cat_cols:\n",
    "    train_test[column] = pd.factorize(train_test[column], sort=True)[0]\n",
    "\n",
    "## Separate the train-test sets    \n",
    "x_train = train_test.iloc[:ntrain, :]\n",
    "x_test = train_test.iloc[ntrain:, :]\n",
    "y_train = loss\n",
    "y_train = y_train.drop(y_train.index[outliers_index]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the above codeblock, let us start experimenting with our dataset and applying PCA to see if it can give us an improved score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=14)\n",
    "pca.fit(cont_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_variance = pca.explained_variance_\n",
    "for element in exp_variance:\n",
    "    print(\"{0:.2f}\".format(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp_variance_ratio = pca.explained_variance_ratio_\n",
    "for element in exp_variance_ratio:\n",
    "    print(\"{0:.2f}\".format(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_df = train[cont_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca.fit(cont_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_df = pca.transform(cont_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont_df = pd.DataFrame(cont_df, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_df = train[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_train = cat_df.join(cont_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_df = test[cont_cols]\n",
    "cont_df = pca.transform(cont_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_df = pd.DataFrame(cont_df, index=None)\n",
    "cat_df = test[cat_cols]\n",
    "new_test = cat_df.join(cont_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Kaggle]",
   "language": "python",
   "name": "conda-env-Kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
